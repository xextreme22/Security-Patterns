# **Integrity Attestation (Remote Attestation)**

## **Intent**
INTEGRITY ATTESTATION is a procedure, that allows a system to proof its maintained integrity state (i.e., that it was not changed in an unauthorized way) to another system.

## **Example**


## **Context**
A client is communicating with an application on a server. The application on the server requires sensitive information from the client (e.g., passwords or pins for online banking) or the authenticity of the information provided by the server is very important to the client. The client wants to check the server’s integrity prior to sending sensitive information to the server.

## **Problem**
The client needs to make sure that the server is in a trustworthy state and the integrity of its running software modules is assured.

The following forces apply:

- Integrity Measurement: The server has to measure properties that reflect its integrity, otherwise the client is not able to verify it.
- Reference Measurement List: The server and the client have to share a pre-agreed measurement list or policy, that defines which measured properties define a maintained integrity. 
- Integrity of Measurement List: Since malicious software may be executed on the server, the integrity and authenticity of the resulting measurement list has to be ensured too.

## **Solution**
A system (prover) proves its integrity to a client (challenger) by taking measurements of properties that reflect its integrity and ensuring that the measurement cannot be tampered with.

## **Structure**
As shown in Figure 17, the Prover is executing a set of SoftwareModules. The PropertyMeasurementUnit is in charge to measure integrity-properties of all modules. These properties have to reflect the integrity of the modules or the overall system (e.g., did somebody tamper with the software module). The MeasurementResults are stored in the ResultStorage. Since potential malicious applications may be executed on the system, the ResultStorage has to be implemented in a way that prevents malicious applications from tampering with it. Moreover, the properties of a module have to be measured before the module is able to forge it (e.g., prior to its execution). Since the connection between the Client and the Prover may be insecure, the integrity and authenticity of the MeasurementResult has to be ensured by a DIGITAL SIGNATURE WITH HASHING. In order to prevent potentially malicious software from forging this signature on the prover, this signature has to be generated by hardware (i.e., the signature key is not accessible by software). The Client compares the MeasuremetnResults with an IntegrityPolicy that defines reference measurements that are considered trustworthy.

![](./Images/integrity_attestation_structure.png)

*Figure 17: INTEGRITY ATTESTATION: The Prover observes its running software modules with the PropertyMeasurementUnit. The measurements*

## **Dynamics**
As shown in Figure 18, the Prover measures all its modules via the PropertyMeasurementUnit. Whenever a Client wants to communicate with the Prover, the Prover signs its MeasurementResults and sends it to the Client. Now, the client compares the received results with the IntegrityPolicy and is able to decide, whether the integrity of the Prover is given. Only if the received list matches the policy, the actual communication is started.

![](./Images/integrity_attestation_dynamics.png)

*Figure 18: INTEGRITY ATTESTATION: The client verifies the integrity of the prover prior to the actual communication.*

## **Implementation**
Similar to INTEGRITY PROTECTION, this pattern can be implemented in different ways. In systems that implement AUTHENTICATED BOOT (a variation of SECURE BOOT), the hash values of executed modules are used as integrity-properties. Another approach is to identify application behavior (similar to SANDBOX) by logging calls to critical system functions and their arguments. It is possible to implement INTEGRITY PROTECTION and measure the integrity of the integrity-protection system. In this case, the Client only has to verify this single measurement. If the integrity-protection system is in place, no modified software can be executed.

## **Example Resolved**


## **Consequences**
Benefits: 

- Integrity Measurement: The integrity of the system’s software modules is identified by the quantification of measurable properties. 
- Reference Measurement List: The integrity policy can be defined based on the client’s requirements of the server’s state. 
- Integrity of Measurement List: The MeasurementResults are stored in a SECURE STORAGE. Thus, malicious software is not able to corrupt this information. 

Liabilities: 

- Reference Measurement List: The IntegrityPolicy on the client has to be up to date in order to enable the client to verify the prover. Thus, it has to be ensured that the IntegrityPolicy conforms to the server’s configuration every time the server gets updated. 
- Integrity of Measurement List: The prover has to ensure that the measurement list cannot be tampered with. This requires special care on the prover platform, as well as on the communication channel.

## **Known Uses**
INTEGRITY ATTESTATION is implemented in many systems in different ways. In [1], this pattern is used to implement access control of devices to computer networks. An application-level implementation, called Integrity Measurement Architecture (IMA), exits for Linux [2]. Other approaches like DR@FT use SANDBOX-based methods [3].

## **See Also**


## **References**

[1] Feng, W., Qin, Y., Yu, A. M., & Feng, D. (2011, November). A DRTM-based method for trusted network connection. In *2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications* (pp. 425-435). IEEE.
[2] Sailer, R., Zhang, X., Jaeger, T., & Van Doorn, L. (2004, August). Design and implementation of a TCG-based integrity measurement architecture. In *USENIX Security symposium* (Vol. 13, No. 2004, pp. 223-238).
[3] Xu, W., Zhang, X., Hu, H., Ahn, G. J., & Seifert, J. P. (2011). Remote attestation with domain-based integrity model and policy analysis. *IEEE Transactions on Dependable and Secure Computing*, *9*(3), 429-442.

## **Sources*
Rauter, T., Höller, A., Iber, J., & Kreiner, C. (2015, July). Patterns for software integrity protection. In *Proceedings of the 20th European Conference on Pattern Languages of Programs* (pp. 1-10).

